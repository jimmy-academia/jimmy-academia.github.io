<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chin-Yuan Yeh</title>
  
  <meta name="author" content="Chin-Yuan Yeh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/prof_pic.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chin-Yuan Yeh</name>
              </p>
              <p>I am a PhD student at <a href="https://www.ntu.edu.tw/english/">National Taiwan University</a>, where I conduct deep learning research, with a focus on preventing AI from personal harm. I am bilingual in both English and Mandarin Chinese.
              </p>
              <p>
              At NTU I've worked on white-box and black-box adversarial attack against image-to-image translation GANs, with potential application on tackling the problem of DeepFake/DeepNude.
              </p>
              <p style="text-align:center">
                <a href="mailto:marrch30@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Chin_Yuan_Yeh_Curriculum_Vitae.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=O54-RPoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/jimmy_cyyeh">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/jimmy-academia">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/prof_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/prof_pic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in adversarial attacks as a tool for probing deep learning models.
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Attack As the Best Defense: Nullifying Image-to-Image Translation GANs via Limit-Aware Adversarial Attack
              </papertitle>
              <br>
              <strong>Chin-Yuan Yeh</strong>, Hsi-Wen Chen, Hong-Han Shuai, De-Nian Yang, Ming-Syan Chen
              <br>
              <em>ICCV</em> 2021
              <br>
              <a href="https://arxiv.org/abs/2110.02516">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=GtmDkHQqA6k&t=9s&ab_channel=JimmyYeh">video</a>
              /
              <a href="https://github.com/jimmy-academia/LaSGSA">source code</a>
              <p></p>
              <p>Query based black-box attack on Image translation GANs, utilizing optimization techniques including: limit-aware sampling, self-guiding prior, and gradient sliding steps. In particular, the self-guiding prior can be extracted solely from the threat model and the target image.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>
              Disrupting Image-Translation-Based DeepFake Algorithms with Adversarial Attacks
              </papertitle>
              <br>
              <strong>Chin-Yuan Yeh</strong>, Hsi-Wen Chen, Shang-Lun Tsai, Sheng-De Wang
              <br>
              <em>WACV Deepfakes and Presentation Attacks in Biometrics workshop</em>, 2020 
              <br>
              <a href="https://github.com/jimmy-academia/Adversarial-Attack-CycleGAN-and-pix2pix">source code</a>
              <p></p>
              <p>White-box attack on CycleGAN, pix2pix, and pix2pixHD to demonstrate the use of adversarial attack against potential DeepFake/DeepNude models. Includes case studies on repeated inference, ensemble attack. </p>
            </td>
          </tr>

        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
